{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW7fhBd+q333/ejOzupHX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imam5555/cerebro/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnscrZgfmY-V",
        "outputId": "f4a9696f-f260-4dee-c80b-e931370db284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok\n"
          ]
        }
      ],
      "source": [
        "!wget -q -c https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz && \\\n",
        "tar -xvzf ngrok-v3-stable-linux-amd64.tgz && \\\n",
        "mv ngrok /usr/local/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2vlMvvW1hzLgdWcct4wrJ8inZas_2NSbTPhXfJHyNgLscVEj6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOW_fVzTniK5",
        "outputId": "1f7ac12c-e025-45a8-cb9b-6ecf2efd92a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q flask pyngrok google-generativeai requests python-dotenv\n",
        "\n",
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "import google.generativeai as genai\n",
        "import requests\n",
        "import re\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Grab API keys\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    SERPAPI_KEY = userdata.get('SERPAPI_KEY')\n",
        "    NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "except:\n",
        "    GOOGLE_API_KEY = \"AIzaSyC9oX_xUDGuRGIV5Nv_l-gK-AKF3gOo4AU\"\n",
        "    SERPAPI_KEY = \"8f8fef7e2f1a50dce79e9d5de43ab0fb50d21a4e389c0eb8e742ca8c9353bad2\"\n",
        "    NGROK_AUTH_TOKEN = \"2vlMvvW1hzLgdWcct4wrJ8inZas_2NSbTPhXfJHyNgLscVEj6\"\n",
        "\n",
        "# Configure API and NGROK\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = NGROK_AUTH_TOKEN\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "real_time_keywords = [\"current\", \"now\", \"latest\", \"today\", \"news\", \"2025\"]\n",
        "\n",
        "def has_real_time_keyword(text):\n",
        "    return any(re.search(rf\"\\\\b{re.escape(keyword)}\\\\b\", text.lower()) for keyword in real_time_keywords)\n",
        "\n",
        "def get_real_time_answer(query):\n",
        "    try:\n",
        "        res = requests.get(\"https://serpapi.com/search\", params={\n",
        "            \"engine\": \"google\", \"q\": query, \"api_key\": SERPAPI_KEY\n",
        "        }).json()\n",
        "        answer, link = None, None\n",
        "        if \"answer_box\" in res:\n",
        "            answer = res[\"answer_box\"].get(\"answer\") or res[\"answer_box\"].get(\"snippet\")\n",
        "        elif \"knowledge_graph\" in res:\n",
        "            answer = res[\"knowledge_graph\"].get(\"description\")\n",
        "        elif \"organic_results\" in res:\n",
        "            r = res[\"organic_results\"][0]\n",
        "            answer = r.get(\"snippet\")\n",
        "            link = r.get(\"link\")\n",
        "        return answer, link\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", None\n",
        "\n",
        "# Flask App\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return render_template_string(html_page)\n",
        "\n",
        "@app.route(\"/submit\", methods=[\"POST\"])\n",
        "def handle_query():\n",
        "    user_input = request.form[\"user_input\"]\n",
        "    result, link = \"\", \"\"\n",
        "    if has_real_time_keyword(user_input):\n",
        "        result, link = get_real_time_answer(user_input)\n",
        "    if not result:\n",
        "        result = model.generate_content(user_input).text\n",
        "    return render_template_string(html_page, result=result, user_input=user_input, link=link)\n",
        "\n",
        "# Public URL via ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Cerebro AI is live at: {public_url}\")\n",
        "\n",
        "# HTML template is too long, load it from separate file or define `html_page` here (already defined in your previous code)\n",
        "\n",
        "# Run Flask app\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1HToIYvniwh",
        "outputId": "8af9e1e2-58f4-493f-8a4d-d993f2a449ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerebro AI is live at: NgrokTunnel: \"https://658c-35-245-180-249.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}